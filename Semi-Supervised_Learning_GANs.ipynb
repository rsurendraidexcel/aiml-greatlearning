{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3. Semi-Supervised Learning GANs.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jQ2yGt2CBHG1","colab_type":"text"},"source":["We investigate semi supervisede learning techniques on the MNIST dataset"]},{"cell_type":"code","metadata":{"id":"-FP7H8zgtuYQ","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import math"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JBw2Mp8JtuYW","colab_type":"text"},"source":["### Load and Prepare Data"]},{"cell_type":"code","metadata":{"id":"LSfvChhstuYX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"203070ac-e78b-4276-b69b-e1f206ccad19","executionInfo":{"status":"ok","timestamp":1560583425197,"user_tz":-330,"elapsed":1132,"user":{"displayName":"Jayanth Rasamsetti","photoUrl":"https://lh6.googleusercontent.com/-QQ1NIoATILo/AAAAAAAAAAI/AAAAAAAAAHs/fyKGAkHR40Q/s64/photo.jpg","userId":"11846414020714355076"}}},"source":["#Load MNIST data\n","(train_x, train_y),(test_x, test_y) = tf.keras.datasets.mnist.load_data()\n","#Shape\n","train_x.shape"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"5tgKko1otuYd","colab_type":"code","colab":{}},"source":["#Reshape images to be 3D\n","train_x = np.reshape(train_x, (-1,28,28,1))\n","test_x = np.reshape(test_x, (-1,28,28,1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2TMfEZv7tuYg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"749f6e87-f055-41e5-9b75-5bd8be62449a","executionInfo":{"status":"ok","timestamp":1560583425713,"user_tz":-330,"elapsed":633,"user":{"displayName":"Jayanth Rasamsetti","photoUrl":"https://lh6.googleusercontent.com/-QQ1NIoATILo/AAAAAAAAAAI/AAAAAAAAAHs/fyKGAkHR40Q/s64/photo.jpg","userId":"11846414020714355076"}}},"source":["train_x.shape, test_x.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((60000, 28, 28, 1), (10000, 28, 28, 1))"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"_bwO_LM0tuYk","colab_type":"code","colab":{}},"source":["#Normalize Data\n","train_x = train_x/127.5 - 1\n","test_x = test_x/127.5 - 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m9zlzXEituYo","colab_type":"text"},"source":["Split Training Data between Supervised and Unsupervised Examples. 10% of the data will be used in Supervised learning while rest of it will be used for UnSupervised Learning."]},{"cell_type":"code","metadata":{"id":"qU9mN_9btuYp","colab_type":"code","colab":{}},"source":["supervised_data_percent = 0.015\n","unsupervised_data_percent = 1 - supervised_data_percent"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JtaNoqr4tuYs","colab_type":"code","colab":{}},"source":["train_x_sup, train_x_unsup, train_y_sup, train_y_unsup = train_test_split(train_x, train_y, \n","                                                                          train_size=supervised_data_percent,\n","                                                                          test_size=unsupervised_data_percent)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"axIoHDsftuYv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"fff2a062-2c76-42d5-bed8-330048efad64","executionInfo":{"status":"ok","timestamp":1560583437142,"user_tz":-330,"elapsed":625,"user":{"displayName":"Jayanth Rasamsetti","photoUrl":"https://lh6.googleusercontent.com/-QQ1NIoATILo/AAAAAAAAAAI/AAAAAAAAAHs/fyKGAkHR40Q/s64/photo.jpg","userId":"11846414020714355076"}}},"source":["train_x_sup.shape"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(900, 28, 28, 1)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"IFBiWddYtuYy","colab_type":"text"},"source":["Following function will do 2 things:\n","\n","1. Convert MNIST labels to One-hot encoding\n","2. Append a column at the end with zeros to indicate Real Image"]},{"cell_type":"code","metadata":{"id":"g64eSPJRtuYz","colab_type":"code","colab":{}},"source":["def prepare_labels(y):\n","    \n","    extended_labels = tf.keras.utils.to_categorical(y, 10)\n","    extended_labels = np.concatenate([extended_labels, np.zeros((extended_labels.shape[0],1))], axis=1)\n","    \n","    return extended_labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BIfZbflZtuY1","colab_type":"text"},"source":["### Build Generator\n","\n","Generator will take 100 random numbers as input and will produce an image of shape (28,28,1). Image data values will be between -1 to 1. "]},{"cell_type":"code","metadata":{"id":"Ms66ffRMtuY2","colab_type":"code","colab":{}},"source":["def generator(input_x, training, reuse=False):\n","    \n","    with tf.variable_scope('Generator', reuse=reuse) as scope:\n","        \n","        #Layer 0\n","        x = tf.keras.layers.Reshape((1,1,100,))(input_x)\n","        \n","        #Layer 1\n","        x = tf.keras.layers.Conv2DTranspose(100, kernel_size=(2,2), strides=1, padding='valid')(x)\n","        x = tf.layers.batch_normalization(x, training=training)\n","        x = tf.keras.activations.relu(x)\n","        \n","        #Layer 2\n","        x = tf.keras.layers.Conv2DTranspose(64, kernel_size=(3,3), strides=2, padding='valid')(x)\n","        x = tf.layers.batch_normalization(x, training=training)\n","        x = tf.keras.activations.relu(x)\n","        \n","        #Layer 3\n","        x = tf.keras.layers.Conv2DTranspose(32, kernel_size=(4,4), strides=2, padding='valid')(x)\n","        x = tf.layers.batch_normalization(x, training=training)\n","        x = tf.keras.activations.relu(x)\n","        \n","        #Layer 4\n","        x = tf.keras.layers.Conv2DTranspose(1, kernel_size=(6,6), strides=2, padding='valid')(x)\n","        x = tf.keras.activations.tanh(x)\n","        \n","        return x       "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YdMOnym2tuY4","colab_type":"text"},"source":["### Build Discriminator\n","\n","Discriminator will Images of shape (28,28,1) as input and will produce a vector with 11 values.\n","\n","- 10 Values for MNIST label Classification\n","- 1 Value for Classifying if image is Fake(1) OR Real(0)"]},{"cell_type":"code","metadata":{"id":"B6r_W6QKtuY5","colab_type":"code","colab":{}},"source":["def discriminator(input_d, p_drop, reuse=True, training = True):\n","    \n","    with tf.variable_scope('Discriminator', reuse=reuse) as scope:\n","        \n","        #Layer 1\n","        x = tf.keras.layers.Conv2D(32, kernel_size=(5,5), strides=2, padding='same')(input_d)\n","        x = tf.keras.layers.Dropout(p_drop)(x)\n","        x = tf.keras.activations.relu(x, alpha=0.2)\n","        \n","        #Layer 2\n","        x = tf.keras.layers.Conv2D(64, kernel_size=(3,3), strides=2, padding='same')(x)\n","        x = tf.layers.batch_normalization(x, training=training)\n","        x = tf.keras.activations.relu(x, alpha=0.2)\n","        \n","        #Layer 3\n","        x = tf.keras.layers.Conv2D(128, kernel_size=(2,2), strides=2, padding='same')(x)\n","        x = tf.layers.batch_normalization(x, training=training)\n","        x = tf.keras.activations.relu(x, alpha=0.2)\n","        x = tf.keras.layers.Dropout(p_drop)(x)\n","        \n","        #Layer 4\n","        x = tf.keras.layers.Conv2D(128, kernel_size=(2,2), strides=2, padding='same')(x)\n","        x = tf.keras.activations.relu(x, alpha=0.2)\n","        \n","        #Layer 5\n","        features = tf.keras.layers.Flatten()(x)\n","        logits = tf.keras.layers.Dense(11)(features)\n","        \n","        return features, logits"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZyfWHDq-tuY7","colab_type":"text"},"source":["### Define Loss\n","\n","Loss will be calculated for the following 3 inputs:\n","\n","1. Real images with actual labels (Supervised Learning)\n","2. Real images with NO labels (Unsupervised Learning)\n","3. Fake images with NO labels (Unsupervised Learning)\n","\n","\n","Loss will be calculated for Discriminator and Generator. \n","\n","#### 1. Discriminator Loss\n","\n","Following will be considered to calculate Loss:\n","\n","Unsupervised:\n","1. Loss to predict Real Image is Real and Not fake.\n","2. Loss to predict Fake Image is Fake and Not Real.\n","\n","Supervised:\n","1. Loss to predict MNIST label classification\n","\n","#### 2. Generator Loss\n","\n","Unsupervised Loss:\n","1. Loss to predict Fake Image as Real\n","2. Feature Mapping loss "]},{"cell_type":"code","metadata":{"id":"aGHXmCoUtuY8","colab_type":"code","colab":{}},"source":["def model_loss(real_un_sup_ip, real_sup_ip, fake_ip, p_drop, training, y):\n","    \n","        \n","    #Get Discriminator output for Real Supervised Data\n","    rs_features, rs_logits = discriminator(real_sup_ip, p_drop, reuse=False, training=training)\n","    \n","    #Get Discriminator output for Real Un-Supervised Data\n","    ru_features, ru_logits = discriminator(real_un_sup_ip, p_drop, reuse=True, training=training)\n","    \n","    #Get Fake images from Generator\n","    fake_images = generator(fake_ip, training=training)\n","    \n","    #Get Dicriminator output for Fake images\n","    fake_features, fake_logits = discriminator(fake_images, p_drop, reuse=True, training=training)\n","    \n","    \n","    #Calculating Discriminator Loss\n","    \n","    #1. Let's calculate Unsupervised Loss for both Real and Fake data\n","    real_un_sup_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=ru_logits[:,-1], \n","                                                                              labels=tf.zeros_like(ru_logits[:,-1])))\n","        \n","    \n","    fake_un_sup_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits[:,-1], \n","                                                                              labels=tf.ones_like(fake_logits[:,-1])))\n","    \n","    #2. Supervised Loss\n","    real_sup_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=rs_logits, \n","                                                                              labels=y))\n","    \n","    d_loss = real_un_sup_loss + fake_un_sup_loss + real_sup_loss\n","    \n","    \n","    #Calculating feature mapping loss for Generator\n","    tmp1 = tf.reduce_mean(ru_features, axis = 0)\n","    tmp2 = tf.reduce_mean(fake_features, axis = 0)\n","    feature_mapping_loss = tf.reduce_mean(tf.square(tmp1 - tmp2))\n","    \n","    #Fake vs Real loss\n","    fake_loss_2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits[:,-1], \n","                                                                              labels=tf.zeros_like(fake_logits[:,-1])))\n","    \n","    #g_loss = feature_mapping_loss +  fake_loss_2\n","    g_loss = fake_loss_2\n","    \n","    rs_class_op = tf.nn.softmax(rs_logits)\n","    \n","    #Calculate Accuracy\n","    correct_prediction = tf.equal(tf.argmax(rs_class_op, axis=1), tf.argmax(y, axis=1))\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","    \n","    return fake_images, d_loss, g_loss, accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"373EM-j9tuZA","colab_type":"text"},"source":["### Model Optimization\n","\n","Training Discriminator and Generator models"]},{"cell_type":"code","metadata":{"id":"8lDFl_5ttuZB","colab_type":"code","colab":{}},"source":["def model_optimization(d_loss, g_loss):\n","    \n","    # Get weights and biases to update. Get them separately for the discriminator and the generator\n","    discriminator_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES , scope='Discriminator')    \n","    generator_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Generator')\n","    \n","    #Minimize loss\n","    d_opt = tf.train.AdamOptimizer(name='d_optimizer').minimize(d_loss, var_list=discriminator_train_vars)\n","    \n","    g_opt = tf.train.AdamOptimizer(name='g_optimizer').minimize(g_loss, var_list=generator_train_vars)\n","    \n","    return d_opt, g_opt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrRwdH02tuZE","colab_type":"text"},"source":["### Training Module"]},{"cell_type":"code","metadata":{"id":"8EOS77H4tuZF","colab_type":"code","colab":{}},"source":["def train(batch_size = 64, epochs = 1000):\n","    \n","    train_D_losses = []\n","    train_G_losses = []\n","    train_Accs  = []\n","    test_D_losses = []\n","    test_G_losses = []\n","    test_Accs = []\n","    noise_size = 100\n","    \n","    \n","    tf.reset_default_graph()\n","    \n","    #Declare Placeholders for input values\n","    real_sup_img = tf.placeholder(tf.float32, shape=(None,28,28,1))\n","    labels = tf.placeholder(tf.int64, shape=(None))\n","    \n","    real_unsup_img = tf.placeholder(tf.float32, shape=(None,28,28,1))\n","    \n","    noise_input = tf.placeholder(tf.float32, shape=(None, noise_size))\n","    \n","    dropout_rate = tf.placeholder(tf.float32)\n","    training = tf.placeholder(tf.bool)\n","    \n","    #Learning rate for Generator and Discriminator\n","    lr_g = tf.placeholder(tf.float32)\n","    lr_d = tf.placeholder(tf.float32)\n","    \n","    \n","    #Build the Graph\n","    fake_images, d_loss, g_loss, accuracy = model_loss(real_unsup_img, real_sup_img, noise_input, dropout_rate, \n","                                                       training, labels)    \n","    d_opt, g_opt = model_optimization(d_loss, g_loss)\n","    \n","    \n","    #Execute Graph\n","    with tf.Session() as sess:\n","        \n","        sess.run(tf.global_variables_initializer())\n","        \n","        for i in range(epochs):\n","            \n","            #90% real images will be unsupervised\n","            unsup_indexes = np.random.randint(0, train_x_unsup.shape[0], size=int(0.9*batch_size))\n","            #10% of images will be supervised\n","            sup_indexes = np.random.randint(0, train_x_sup.shape[0], size=int(0.1*batch_size))\n","            \n","            \n","            train_feed_dict = {real_sup_img: train_x_sup[sup_indexes], \n","                         labels: prepare_labels(train_y_sup[sup_indexes]), \n","                         real_unsup_img: train_x_unsup[unsup_indexes], \n","                         noise_input: np.random.uniform(-1.0, 1.0, size = (batch_size, 100)), \n","                         dropout_rate: 0.5,\n","                         training: True,\n","                         lr_g: 1e-5, \n","                         lr_d: 1e-5}\n","            \n","            _,_, dloss, gloss, acc = sess.run([d_opt, g_opt, d_loss, g_loss, accuracy], feed_dict=train_feed_dict)\n","            \n","            \n","            #Calculate Loss and Accuracy for Test Data\n","            if i % 200 == 0:\n","                \n","                print(i, '. Training Acc', acc, end='\\t')\n","                train_Accs.append(acc)\n","                \n","                test_feed_dict = {real_sup_img: test_x, \n","                         labels: prepare_labels(test_y), \n","                         real_unsup_img: test_x, \n","                         noise_input: np.random.uniform(-1.0, 1.0, size = (batch_size, 100)), \n","                         dropout_rate: 0,\n","                         training: False}\n","                \n","                t_dloss, t_gloss, t_acc, fakeImgs = sess.run([d_loss, g_loss, accuracy, fake_images], \n","                                                             feed_dict=test_feed_dict)\n","                \n","                test_Accs.append(t_acc)\n","                \n","                print('Test Acc', t_acc)\n","    return train_Accs, test_Accs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dtgFn-fvtuZI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2043},"outputId":"818967be-7fc4-43d0-f654-a5e35571511d","executionInfo":{"status":"ok","timestamp":1560583710623,"user_tz":-330,"elapsed":234980,"user":{"displayName":"Jayanth Rasamsetti","photoUrl":"https://lh6.googleusercontent.com/-QQ1NIoATILo/AAAAAAAAAAI/AAAAAAAAAHs/fyKGAkHR40Q/s64/photo.jpg","userId":"11846414020714355076"}}},"source":["accs, val_accs = train(batch_size=32,epochs=20000)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0615 07:24:36.095830 139688085026688 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0615 07:24:36.177558 139688085026688 deprecation.py:323] From <ipython-input-11-c6f9ac8af9a2>:12: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n","W0615 07:24:37.081521 139688085026688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0615 07:24:37.107459 139688085026688 deprecation.py:323] From <ipython-input-12-446ecc0d69b4>:29: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["0 . Training Acc 0.0\tTest Acc 0.1803\n","200 . Training Acc 0.6666667\tTest Acc 0.7484\n","400 . Training Acc 1.0\tTest Acc 0.884\n","600 . Training Acc 1.0\tTest Acc 0.8979\n","800 . Training Acc 1.0\tTest Acc 0.9089\n","1000 . Training Acc 1.0\tTest Acc 0.8949\n","1200 . Training Acc 1.0\tTest Acc 0.9139\n","1400 . Training Acc 1.0\tTest Acc 0.899\n","1600 . Training Acc 1.0\tTest Acc 0.89\n","1800 . Training Acc 1.0\tTest Acc 0.9269\n","2000 . Training Acc 1.0\tTest Acc 0.8995\n","2200 . Training Acc 1.0\tTest Acc 0.8924\n","2400 . Training Acc 1.0\tTest Acc 0.8982\n","2600 . Training Acc 1.0\tTest Acc 0.9188\n","2800 . Training Acc 1.0\tTest Acc 0.875\n","3000 . Training Acc 1.0\tTest Acc 0.9098\n","3200 . Training Acc 1.0\tTest Acc 0.9117\n","3400 . Training Acc 1.0\tTest Acc 0.8926\n","3600 . Training Acc 1.0\tTest Acc 0.87\n","3800 . Training Acc 1.0\tTest Acc 0.9163\n","4000 . Training Acc 1.0\tTest Acc 0.9147\n","4200 . Training Acc 1.0\tTest Acc 0.9344\n","4400 . Training Acc 1.0\tTest Acc 0.8877\n","4600 . Training Acc 1.0\tTest Acc 0.8798\n","4800 . Training Acc 1.0\tTest Acc 0.9061\n","5000 . Training Acc 1.0\tTest Acc 0.9016\n","5200 . Training Acc 1.0\tTest Acc 0.9297\n","5400 . Training Acc 1.0\tTest Acc 0.9274\n","5600 . Training Acc 1.0\tTest Acc 0.8901\n","5800 . Training Acc 1.0\tTest Acc 0.924\n","6000 . Training Acc 1.0\tTest Acc 0.9025\n","6200 . Training Acc 1.0\tTest Acc 0.9149\n","6400 . Training Acc 1.0\tTest Acc 0.9161\n","6600 . Training Acc 1.0\tTest Acc 0.9219\n","6800 . Training Acc 1.0\tTest Acc 0.9042\n","7000 . Training Acc 1.0\tTest Acc 0.9211\n","7200 . Training Acc 1.0\tTest Acc 0.9045\n","7400 . Training Acc 1.0\tTest Acc 0.928\n","7600 . Training Acc 1.0\tTest Acc 0.9112\n","7800 . Training Acc 1.0\tTest Acc 0.9249\n","8000 . Training Acc 1.0\tTest Acc 0.9256\n","8200 . Training Acc 1.0\tTest Acc 0.9101\n","8400 . Training Acc 1.0\tTest Acc 0.9124\n","8600 . Training Acc 1.0\tTest Acc 0.9283\n","8800 . Training Acc 1.0\tTest Acc 0.9012\n","9000 . Training Acc 1.0\tTest Acc 0.92\n","9200 . Training Acc 1.0\tTest Acc 0.9268\n","9400 . Training Acc 1.0\tTest Acc 0.9302\n","9600 . Training Acc 1.0\tTest Acc 0.9316\n","9800 . Training Acc 1.0\tTest Acc 0.9263\n","10000 . Training Acc 1.0\tTest Acc 0.9281\n","10200 . Training Acc 1.0\tTest Acc 0.8898\n","10400 . Training Acc 1.0\tTest Acc 0.8613\n","10600 . Training Acc 1.0\tTest Acc 0.9053\n","10800 . Training Acc 1.0\tTest Acc 0.9169\n","11000 . Training Acc 1.0\tTest Acc 0.94\n","11200 . Training Acc 1.0\tTest Acc 0.9359\n","11400 . Training Acc 1.0\tTest Acc 0.9291\n","11600 . Training Acc 1.0\tTest Acc 0.8948\n","11800 . Training Acc 1.0\tTest Acc 0.9345\n","12000 . Training Acc 1.0\tTest Acc 0.9398\n","12200 . Training Acc 1.0\tTest Acc 0.9422\n","12400 . Training Acc 1.0\tTest Acc 0.9421\n","12600 . Training Acc 1.0\tTest Acc 0.9427\n","12800 . Training Acc 1.0\tTest Acc 0.9425\n","13000 . Training Acc 1.0\tTest Acc 0.9428\n","13200 . Training Acc 1.0\tTest Acc 0.9423\n","13400 . Training Acc 1.0\tTest Acc 0.9425\n","13600 . Training Acc 1.0\tTest Acc 0.9427\n","13800 . Training Acc 1.0\tTest Acc 0.9427\n","14000 . Training Acc 1.0\tTest Acc 0.943\n","14200 . Training Acc 1.0\tTest Acc 0.9432\n","14400 . Training Acc 1.0\tTest Acc 0.943\n","14600 . Training Acc 1.0\tTest Acc 0.9431\n","14800 . Training Acc 1.0\tTest Acc 0.9431\n","15000 . Training Acc 1.0\tTest Acc 0.9432\n","15200 . Training Acc 1.0\tTest Acc 0.9432\n","15400 . Training Acc 1.0\tTest Acc 0.9425\n","15600 . Training Acc 1.0\tTest Acc 0.9429\n","15800 . Training Acc 1.0\tTest Acc 0.9429\n","16000 . Training Acc 1.0\tTest Acc 0.943\n","16200 . Training Acc 1.0\tTest Acc 0.9433\n","16400 . Training Acc 1.0\tTest Acc 0.9431\n","16600 . Training Acc 1.0\tTest Acc 0.9431\n","16800 . Training Acc 1.0\tTest Acc 0.9432\n","17000 . Training Acc 1.0\tTest Acc 0.9437\n","17200 . Training Acc 1.0\tTest Acc 0.9439\n","17400 . Training Acc 1.0\tTest Acc 0.9439\n","17600 . Training Acc 1.0\tTest Acc 0.944\n","17800 . Training Acc 1.0\tTest Acc 0.9441\n","18000 . Training Acc 1.0\tTest Acc 0.9439\n","18200 . Training Acc 1.0\tTest Acc 0.9437\n","18400 . Training Acc 1.0\tTest Acc 0.9442\n","18600 . Training Acc 1.0\tTest Acc 0.9445\n","18800 . Training Acc 1.0\tTest Acc 0.9445\n","19000 . Training Acc 1.0\tTest Acc 0.9444\n","19200 . Training Acc 1.0\tTest Acc 0.9444\n","19400 . Training Acc 1.0\tTest Acc 0.9225\n","19600 . Training Acc 1.0\tTest Acc 0.9293\n","19800 . Training Acc 1.0\tTest Acc 0.7009\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e7FmDa5TtuZM","colab_type":"code","colab":{}},"source":["def plot_images(fake_images):\n","    \n","    plt.figure(figsize=(2.2, 2.2))\n","    num_images = 16\n","    \n","    image_size = 28\n","    rows = 4\n","    \n","    for i in range(num_images):\n","        plt.subplot(rows, rows, i + 1)\n","        image = np.reshape(fake_images[i], [image_size, image_size])\n","        image = (image + 1)/2\n","        plt.imshow(image, cmap='gray')\n","        plt.axis('off')\n","    plt.show()   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KRMuzkP1Bjle","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}